{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Our CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, file, show=False):\n",
    "    # takes in a AWS S3 url\n",
    "    spark = SparkSession.builder.appName(\"Project_ETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()\n",
    "    spark.sparkContext.addFile(url)\n",
    "    df = spark.read.csv(SparkFiles.get(file), sep=\",\", header=True, inferSchema=True)\n",
    "    df = df.toPandas()\n",
    "    if show == True:\n",
    "        display(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "# file names\n",
    "math_file = \"student-mat.csv\"\n",
    "por_file = \"student-por.csv\"\n",
    "# file urls\n",
    "math_url = f\"https://burdenderek-project.s3.us-east-2.amazonaws.com/{math_file}\"\n",
    "por_url = f\"https://burdenderek-project.s3.us-east-2.amazonaws.com/{por_file}\"\n",
    "# save the dataframes\n",
    "math = extract(url=math_url, file=math_file)\n",
    "por = extract(url=por_url, file=por_file)\n",
    "# math_path = os.path.join(\"Student_alcohol_consumption\", \"student-mat.csv\")\n",
    "# por_path = os.path.join(\"Student_alcohol_consumption\", \"student-por.csv\")\n",
    "# math = pd.read_csv(math_path)\n",
    "# por = pd.read_csv(por_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences G1 G2 G3  \n",
       "0      4        3      4     1     1      3        6  0  0  0  \n",
       "1      5        3      3     1     1      3        4  0  0  0  \n",
       "2      4        3      2     2     3      3       10  0  0  1  \n",
       "3      3        2      2     1     1      5        2  1  1  1  \n",
       "4      4        3      2     1     2      5        4  0  1  1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences G1 G2 G3  \n",
       "0      4        3      4     1     1      3        4  0  1  1  \n",
       "1      5        3      3     1     1      3        2  0  1  1  \n",
       "2      4        3      2     2     3      3        6  1  1  1  \n",
       "3      3        2      2     1     1      5        0  1  1  1  \n",
       "4      4        3      2     1     2      5        0  1  1  1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean bucket the grades\n",
    "# 10 and above is a pass\n",
    "# 9 and below is a fail\n",
    "\n",
    "def encode_grades(data):\n",
    "    # bucket the grades into passing(1) and failling(0)\n",
    "    \n",
    "    # math\n",
    "    # failling\n",
    "    data.loc[(data[\"G1\"] < 10), \"G1\"] = 0\n",
    "    data.loc[(data[\"G2\"] < 10), \"G2\"] = 0\n",
    "    data.loc[(data[\"G3\"] < 10), \"G3\"] = 0\n",
    "\n",
    "    #passing\n",
    "    data.loc[(data[\"G1\"] >= 10), \"G1\"] = 1\n",
    "    data.loc[(data[\"G2\"] >= 10), \"G2\"] = 1\n",
    "    data.loc[(data[\"G3\"] >= 10), \"G3\"] = 1\n",
    "    \n",
    "    display(data.head())\n",
    "    \n",
    "    return\n",
    "\n",
    "encode_grades(math)\n",
    "encode_grades(por)\n",
    "\n",
    "dnn_math = math.copy()\n",
    "dnn_por = por.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0         0    0    3        1        0        0     4     4     0     4  ...   \n",
       "1         0    0    2        1        0        1     1     1     0     2  ...   \n",
       "2         0    0    0        1        1        1     1     1     0     2  ...   \n",
       "3         0    0    0        1        0        1     4     2     1     3  ...   \n",
       "4         0    0    1        1        0        1     3     3     2     2  ...   \n",
       "..      ...  ...  ...      ...      ...      ...   ...   ...   ...   ...  ...   \n",
       "390       1    1    5        1        1        0     2     2     3     3  ...   \n",
       "391       1    1    2        1        1        1     3     1     3     3  ...   \n",
       "392       1    1    6        0        0        1     1     1     2     2  ...   \n",
       "393       1    1    3        0        1        1     3     2     3     2  ...   \n",
       "394       1    1    4        1        1        1     1     1     2     0  ...   \n",
       "\n",
       "     famrel  freetime  goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0         3         2      3     0     0       2         6   0   0   0  \n",
       "1         4         2      2     0     0       2         4   0   0   0  \n",
       "2         3         2      1     1     2       2        10   0   0   1  \n",
       "3         2         1      1     0     0       4         2   1   1   1  \n",
       "4         3         2      1     0     1       4         4   0   1   1  \n",
       "..      ...       ...    ...   ...   ...     ...       ...  ..  ..  ..  \n",
       "390       4         4      3     3     4       3        11   0   0   0  \n",
       "391       1         3      4     2     3       1         3   1   1   1  \n",
       "392       4         4      2     2     2       2         3   1   0   0  \n",
       "393       3         3      0     2     3       4         0   1   1   1  \n",
       "394       2         1      2     2     2       4         5   0   0   0  \n",
       "\n",
       "[395 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0         0    0    3        1        0        0     4     4     0     4  ...   \n",
       "1         0    0    2        1        0        1     1     1     0     2  ...   \n",
       "2         0    0    0        1        1        1     1     1     0     2  ...   \n",
       "3         0    0    0        1        0        1     4     2     1     3  ...   \n",
       "4         0    0    1        1        0        1     3     3     2     2  ...   \n",
       "..      ...  ...  ...      ...      ...      ...   ...   ...   ...   ...  ...   \n",
       "644       1    0    4        0        0        1     2     3     3     2  ...   \n",
       "645       1    0    3        1        1        1     3     1     4     3  ...   \n",
       "646       1    0    3        1        0        1     1     1     2     2  ...   \n",
       "647       1    1    2        1        1        1     3     1     3     3  ...   \n",
       "648       1    1    3        0        1        1     3     2     3     2  ...   \n",
       "\n",
       "     famrel  freetime  goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0         3         2      3     0     0       2         4   0   1   1  \n",
       "1         4         2      2     0     0       2         2   0   1   1  \n",
       "2         3         2      1     1     2       2         6   1   1   1  \n",
       "3         2         1      1     0     0       4         0   1   1   1  \n",
       "4         3         2      1     0     1       4         0   1   1   1  \n",
       "..      ...       ...    ...   ...   ...     ...       ...  ..  ..  ..  \n",
       "644       4         3      1     0     1       4         4   1   1   1  \n",
       "645       3         2      3     0     0       0         4   1   1   1  \n",
       "646       0         0      0     0     0       4         6   1   1   0  \n",
       "647       1         3      4     2     3       1         6   1   1   1  \n",
       "648       3         3      0     2     3       4         4   1   1   1  \n",
       "\n",
       "[649 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode_features(data):\n",
    "\n",
    "    for i in data.columns.tolist():\n",
    "        le = LabelEncoder()\n",
    "        data[i] = le.fit_transform(data[i])\n",
    "        \n",
    "    display(data)\n",
    "    \n",
    "    return\n",
    "\n",
    "encode_features(math)\n",
    "encode_features(por)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions to Build Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample(df, drop, target):\n",
    "    \n",
    "    # split the table into features and outcomes\n",
    "    x_cols = [i for i in df.columns if i not in drop]\n",
    "    X = df[x_cols]\n",
    "    y = df[target]\n",
    "\n",
    "    # split features and outcomes into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    # oversample to make up for the low number of risky loans\n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculating the accuracy score.\n",
    "    acc_score = balanced_accuracy_score(y_test, y_predictions)\n",
    "    \n",
    "    return acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(df, drop, target):\n",
    "    \n",
    "    # split the table into features and outcomes\n",
    "    x_cols = [i for i in df.columns if i not in drop]\n",
    "    X = df[x_cols]\n",
    "    y = df[target]\n",
    "\n",
    "    # split features and outcomes into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    ros = RandomUnderSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculating the accuracy score.\n",
    "    acc_score = balanced_accuracy_score(y_test, y_predictions)\n",
    "    \n",
    "    return acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(df, drop, target):\n",
    "    \n",
    "    # split the table into features and outcomes\n",
    "    x_cols = [i for i in df.columns if i not in drop]\n",
    "    X = df[x_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    # split features and outcomes into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    cc = ClusterCentroids(random_state=1)\n",
    "    X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "\n",
    "    y_predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculating the accuracy score.\n",
    "    acc_score = balanced_accuracy_score(y_test, y_predictions)\n",
    "    \n",
    "    return acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteen(df, drop, target):\n",
    "    \n",
    "    # split the table into features and outcomes\n",
    "    x_cols = [i for i in df.columns if i not in drop]\n",
    "    X = df[x_cols]\n",
    "    y = df[target]\n",
    "\n",
    "    # split features and outcomes into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculating the accuracy score.\n",
    "    acc_score = balanced_accuracy_score(y_test, y_predictions)\n",
    "    \n",
    "    return acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df, drop, target, show, model_name):\n",
    "\n",
    "    # split the table into features and outcomes\n",
    "    x_cols = [i for i in df.columns if i not in drop]\n",
    "    X = df[x_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    # split features and outcomes into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    brf = BalancedRandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    brf.fit(X_train, y_train)\n",
    "    y_predictions = brf.predict(X_test)\n",
    "\n",
    "    feature_importance = sorted(zip(brf.feature_importances_, X.columns.tolist()))[::-1]\n",
    "\n",
    "    # Calculating the accuracy score.\n",
    "    acc_score = balanced_accuracy_score(y_test, y_predictions)\n",
    "\n",
    "    # Displaying results\n",
    "    if show == True:\n",
    "        print(f\"Feature Importance: {model_name}\")\n",
    "        for i in feature_importance:\n",
    "            print(i)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    return acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_ensemble_classifier(df, drop, target):\n",
    "    \n",
    "    # split the table into features and outcomes\n",
    "    x_cols = [i for i in df.columns if i not in drop]\n",
    "    X = df[x_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    # split features and outcomes into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    eec = EasyEnsembleClassifier(n_estimators=100, random_state=0)\n",
    "    eec.fit(X_train, y_train)\n",
    "    y_predictions = eec.predict(X_test)\n",
    "\n",
    "    # Calculating the accuracy score.\n",
    "    acc_score = balanced_accuracy_score(y_test, y_predictions)\n",
    "    \n",
    "    return acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(df, drop, target, file_name):\n",
    "\n",
    "    # Generate our categorical variable list\n",
    "    encode_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "    # Check the number of unique values in each column\n",
    "    df[encode_cat].nunique()\n",
    "\n",
    "    # Create the OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit the encoder and produce encoded DataFrame\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[encode_cat]))\n",
    "\n",
    "    # Rename encoded columns\n",
    "    encode_df.columns = enc.get_feature_names(encode_cat)\n",
    "\n",
    "    # Merge the two DataFrames together and drop the Country column\n",
    "    df = df.merge(encode_df,left_index=True,right_index=True).drop(encode_cat, 1)\n",
    "\n",
    "    # Split our preprocessed data into our features and target arrays\n",
    "    y = df[target].values\n",
    "    X = df.drop(drop,1).values\n",
    "\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, shuffle=False)\n",
    "\n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the StandardScaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    # Save the scaler\n",
    "    #pickle.dump(X_scaler, open(\"scaler.sav\", \"wb\"))\n",
    "\n",
    "    # Scale the data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Define the model - deep neural net\n",
    "    number_input_features = len(X_train[0])\n",
    "    hidden_nodes_layer1 =  len(X_train[0]) * 2\n",
    "    hidden_nodes_layer2 = len(X_train[0]) * .1\n",
    "\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "    # Second hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    fit_model = nn.fit(X_train_scaled,y_train,epochs=50, verbose=0)\n",
    "    \n",
    "    # We are going to do a slightly round about method to test our model\n",
    "    # We are saving and exporting the model then importing it back in\n",
    "    # This is for two reasons\n",
    "    # First reason is that we want to save our trained models\n",
    "    # But we do not need it reimport it to test its accuracy, so why are we doing this?\n",
    "    # We are testing the imported model because we want to make sure that the model file works\n",
    "    \n",
    "    # save model\n",
    "    file_path = os.path.join(\"models\", file_name)\n",
    "    nn.save(file_path)\n",
    "    \n",
    "    # import model back in\n",
    "    nn_imported = tf.keras.models.load_model(file_path)\n",
    "\n",
    "    # Evaluate the model using the test data\n",
    "    model_loss, model_accuracy = nn_imported.evaluate(X_test_scaled,y_test, verbose=0)\n",
    "    \n",
    "    return model_accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We do not want to have to run 6 functions for each target so lets make a function that will handle it.\n",
    "###### This function will build models for the given target, then format the results into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(df, drop, target, model_name, show, file_name, dnn_df):\n",
    "    \n",
    "    # make a dataframe to neatly organize our results\n",
    "    machine_learning_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Target\": model_name,\n",
    "            \"Over Sampling\": [over_sample(df, drop, target)],\n",
    "            \"Under Sampling\": [under_sample(df, drop, target)],\n",
    "            \"Cluster Centroids\": [cluster(df, drop, target)],\n",
    "            \"SMOTEENN\": [smoteen(df, drop, target)],\n",
    "            \"Random Forest\": [random_forest(df, drop, target, show, model_name)],\n",
    "            \"Easy Ensemble Classifier\": [easy_ensemble_classifier(df, drop, target)],\n",
    "            \"Deep Neural Network\": [dnn(dnn_df, drop, target, file_name)]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # format the accuracy scores to make them easier to read and more descriptive\n",
    "    machine_learning_summary[\"Over Sampling\"] = machine_learning_summary[\"Over Sampling\"].map(\"{:.1f}%\".format)\n",
    "    machine_learning_summary[\"Under Sampling\"] = machine_learning_summary[\"Under Sampling\"].map(\"{:.1f}%\".format)\n",
    "    machine_learning_summary[\"Cluster Centroids\"] = machine_learning_summary[\"Cluster Centroids\"].map(\"{:.1f}%\".format)\n",
    "    machine_learning_summary[\"SMOTEENN\"] = machine_learning_summary[\"SMOTEENN\"].map(\"{:.1f}%\".format)\n",
    "    machine_learning_summary[\"Random Forest\"] = machine_learning_summary[\"Random Forest\"].map(\"{:.1f}%\".format)\n",
    "    machine_learning_summary[\"Easy Ensemble Classifier\"] = machine_learning_summary[\"Easy Ensemble Classifier\"].map(\"{:.1f}%\".format)\n",
    "    machine_learning_summary[\"Deep Neural Network\"] = machine_learning_summary[\"Deep Neural Network\"].map(\"{:.1f}%\".format)\n",
    "    \n",
    "    # change the index name it more clearly state that it is the accuracy scores being displayed\n",
    "    #machine_learning_summary = machine_learning_summary.rename(index={0: \"Accuracy Score\"})\n",
    "    machine_learning_summary = machine_learning_summary.set_index(\"Target\")\n",
    "    # show us the dataframe\n",
    "    #display(machine_learning_summary)\n",
    "    \n",
    "    return machine_learning_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slightly unnecessary, but it would be even more nice to only have to run one function to check all the targets.\n",
    "###### This function combines all of the summary tables into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_table(show=False):\n",
    "\n",
    "    # different columns to drop depending on which target we are using\n",
    "    # we are not dropping previous grades because it is a reasonable expectation to have those data points sequential trimesters\n",
    "    G1 = [\"G1\", \"G2\", \"G3\"]\n",
    "    G2 = [\"G2\", \"G3\"]\n",
    "    G3 = [\"G3\"]\n",
    "    \n",
    "    # names from our different model targets\n",
    "    models = [\n",
    "        \"Math G1\",\n",
    "        \"Math G2\",\n",
    "        \"Math G3\",\n",
    "        \"Portuguese G1\",\n",
    "        \"Portuguese G2\",\n",
    "        \"Portuguese G3\"\n",
    "    ]\n",
    "    \n",
    "    # names for the different file names\n",
    "    file = [\n",
    "        \"trained_math_G1.h5\",\n",
    "        \"trained_math_G2.h5\",\n",
    "        \"trained_math_G3.h5\",\n",
    "        \"trained_por_G1.h5\",\n",
    "        \"trained_por_G2.h5\",\n",
    "        \"trained_por_G3.h5\"\n",
    "    ]\n",
    "    \n",
    "    summary_table = model_summary(df=math, drop=G1, target=\"G1\", model_name=models[0], show=show, file_name=file[0], dnn_df=dnn_math)\n",
    "    summary_table = summary_table.append(model_summary(df=math, drop=G2, target=\"G2\", model_name=models[1], show=show, file_name=file[1], dnn_df=dnn_math))\n",
    "    summary_table = summary_table.append(model_summary(df=math, drop=G3, target=\"G3\", model_name=models[2], show=show, file_name=file[2], dnn_df=dnn_math))\n",
    "    summary_table = summary_table.append(model_summary(df=por, drop=G1, target=\"G1\", model_name=models[3], show=show, file_name=file[3], dnn_df=dnn_por))\n",
    "    summary_table = summary_table.append(model_summary(df=por, drop=G2, target=\"G2\", model_name=models[4], show=show, file_name=file[4], dnn_df=dnn_por))\n",
    "    summary_table = summary_table.append(model_summary(df=por, drop=G3, target=\"G3\", model_name=models[5], show=show, file_name=file[5], dnn_df=dnn_por))\n",
    "    \n",
    "    display(summary_table)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance: Math G1\n",
      "(0.07552015588930218, 'absences')\n",
      "(0.0741165088766574, 'Fedu')\n",
      "(0.060873078960852305, 'failures')\n",
      "(0.053474408784157504, 'studytime')\n",
      "(0.05236555674811134, 'Mjob')\n",
      "(0.04818087755809755, 'freetime')\n",
      "(0.0474152549255183, 'Medu')\n",
      "(0.0458958103540737, 'age')\n",
      "(0.043323686736156955, 'health')\n",
      "(0.04246381335711076, 'Walc')\n",
      "(0.040331573845309214, 'goout')\n",
      "(0.03700496526341975, 'reason')\n",
      "(0.03539569852804747, 'Dalc')\n",
      "(0.03447889596108349, 'famrel')\n",
      "(0.030414449343871008, 'Fjob')\n",
      "(0.026008284858731967, 'guardian')\n",
      "(0.025681861660632268, 'traveltime')\n",
      "(0.02405448454967536, 'schoolsup')\n",
      "(0.021293562166722343, 'sex')\n",
      "(0.020586250395254812, 'paid')\n",
      "(0.020534523118049552, 'famsup')\n",
      "(0.019635232328878875, 'famsize')\n",
      "(0.01877966589770088, 'nursery')\n",
      "(0.017732042723502848, 'activities')\n",
      "(0.0176433631554651, 'address')\n",
      "(0.016309761074637903, 'romantic')\n",
      "(0.015339006376218548, 'internet')\n",
      "(0.01364691941038523, 'Pstatus')\n",
      "(0.01306803472392071, 'school')\n",
      "(0.008432272428454759, 'higher')\n",
      "\n",
      "\n",
      "Feature Importance: Math G2\n",
      "(0.28863992658328863, 'G1')\n",
      "(0.052207841118592294, 'absences')\n",
      "(0.04571837557279182, 'goout')\n",
      "(0.03687566644555507, 'age')\n",
      "(0.03585529646619073, 'Medu')\n",
      "(0.0354552788167293, 'failures')\n",
      "(0.0354028078691229, 'Mjob')\n",
      "(0.03479662462056467, 'Walc')\n",
      "(0.03335591122582404, 'studytime')\n",
      "(0.030952817785297432, 'health')\n",
      "(0.03000288862847583, 'reason')\n",
      "(0.029867794158010785, 'Fedu')\n",
      "(0.02905847696340761, 'freetime')\n",
      "(0.02730717348877115, 'famrel')\n",
      "(0.023468272345419282, 'Fjob')\n",
      "(0.021571071085908926, 'Dalc')\n",
      "(0.021480385029389978, 'traveltime')\n",
      "(0.018800888605443215, 'romantic')\n",
      "(0.016952610606687367, 'sex')\n",
      "(0.015546496957724571, 'guardian')\n",
      "(0.014981040096361788, 'internet')\n",
      "(0.014727370340730914, 'nursery')\n",
      "(0.01434080113794993, 'schoolsup')\n",
      "(0.014184205540133242, 'address')\n",
      "(0.014107237335899225, 'activities')\n",
      "(0.013642029766365383, 'famsize')\n",
      "(0.01340509890505034, 'paid')\n",
      "(0.013027356311678409, 'famsup')\n",
      "(0.009476888065275791, 'Pstatus')\n",
      "(0.009313508778853334, 'school')\n",
      "(0.005477859348506021, 'higher')\n",
      "\n",
      "\n",
      "Feature Importance: Math G3\n",
      "(0.35239341535180474, 'G2')\n",
      "(0.16140828041995653, 'G1')\n",
      "(0.03765691304697964, 'age')\n",
      "(0.03404896844677103, 'absences')\n",
      "(0.03187628672835719, 'Mjob')\n",
      "(0.026945336389663385, 'failures')\n",
      "(0.025213612035328067, 'Fedu')\n",
      "(0.023633294789985312, 'goout')\n",
      "(0.022544619047961414, 'reason')\n",
      "(0.02186733813776867, 'health')\n",
      "(0.020782124659347482, 'Walc')\n",
      "(0.019600043042871006, 'Fjob')\n",
      "(0.018946511533406783, 'famrel')\n",
      "(0.018467095470596467, 'studytime')\n",
      "(0.018319505647276347, 'Medu')\n",
      "(0.016396610112998138, 'freetime')\n",
      "(0.015821512400383084, 'Dalc')\n",
      "(0.015128232079602195, 'traveltime')\n",
      "(0.012962806709991363, 'romantic')\n",
      "(0.011830917202268976, 'paid')\n",
      "(0.011426023837068217, 'schoolsup')\n",
      "(0.011257580593511196, 'famsup')\n",
      "(0.010033693155955401, 'guardian')\n",
      "(0.008733541073861747, 'activities')\n",
      "(0.008003051765965464, 'sex')\n",
      "(0.007717559387730274, 'address')\n",
      "(0.007713416172504746, 'internet')\n",
      "(0.007223986930590042, 'famsize')\n",
      "(0.006157782210307946, 'nursery')\n",
      "(0.0060567659942581285, 'higher')\n",
      "(0.004946857263339656, 'Pstatus')\n",
      "(0.004886318361589365, 'school')\n",
      "\n",
      "\n",
      "Feature Importance: Portuguese G1\n",
      "(0.09579429744829426, 'failures')\n",
      "(0.06706836831568816, 'higher')\n",
      "(0.0664489527948748, 'studytime')\n",
      "(0.06559163458277897, 'school')\n",
      "(0.05900998104671517, 'absences')\n",
      "(0.04497840546983853, 'Mjob')\n",
      "(0.04330958054895195, 'age')\n",
      "(0.042537650000873735, 'Medu')\n",
      "(0.04150144349655257, 'goout')\n",
      "(0.040854216872183366, 'freetime')\n",
      "(0.03846448154555924, 'Walc')\n",
      "(0.03681073671426084, 'Fedu')\n",
      "(0.03670905512447194, 'famrel')\n",
      "(0.03014180155140863, 'reason')\n",
      "(0.029133913820777554, 'health')\n",
      "(0.028027281350105782, 'Fjob')\n",
      "(0.026403079783801707, 'traveltime')\n",
      "(0.026346294809389815, 'Dalc')\n",
      "(0.02204389550016124, 'guardian')\n",
      "(0.020902420139331503, 'activities')\n",
      "(0.01959833012620774, 'address')\n",
      "(0.01931751695398588, 'sex')\n",
      "(0.01649691283132517, 'famsup')\n",
      "(0.015124924426826964, 'romantic')\n",
      "(0.014226231818354704, 'famsize')\n",
      "(0.013059504450413897, 'internet')\n",
      "(0.012596304796218413, 'schoolsup')\n",
      "(0.011944867061325179, 'nursery')\n",
      "(0.009213168958640354, 'Pstatus')\n",
      "(0.006344747660682002, 'paid')\n",
      "\n",
      "\n",
      "Feature Importance: Portuguese G2\n",
      "(0.22511796939297032, 'G1')\n",
      "(0.06888819848964638, 'failures')\n",
      "(0.04843889980403394, 'absences')\n",
      "(0.03718721401588087, 'goout')\n",
      "(0.036513869146892905, 'Fedu')\n",
      "(0.03613692484559296, 'reason')\n",
      "(0.035077171781173234, 'age')\n",
      "(0.03507285505209215, 'studytime')\n",
      "(0.03452395396895953, 'freetime')\n",
      "(0.03412427608186755, 'Walc')\n",
      "(0.03407126044412472, 'famrel')\n",
      "(0.030756070317026526, 'health')\n",
      "(0.030105204317525166, 'Medu')\n",
      "(0.027688237671757192, 'Mjob')\n",
      "(0.027100733431234092, 'school')\n",
      "(0.02605367964595538, 'sex')\n",
      "(0.025132421208691483, 'Dalc')\n",
      "(0.02381162661784975, 'higher')\n",
      "(0.023207296817018476, 'Fjob')\n",
      "(0.021842109776796726, 'traveltime')\n",
      "(0.01768730305646594, 'guardian')\n",
      "(0.016043228319594566, 'activities')\n",
      "(0.015939422187820428, 'nursery')\n",
      "(0.015176837205396566, 'romantic')\n",
      "(0.013983200345026996, 'address')\n",
      "(0.013597931652410113, 'internet')\n",
      "(0.013402180263573807, 'famsup')\n",
      "(0.013185520223330112, 'famsize')\n",
      "(0.009818611789487291, 'schoolsup')\n",
      "(0.005946813715630848, 'Pstatus')\n",
      "(0.004368978414173946, 'paid')\n",
      "\n",
      "\n",
      "Feature Importance: Portuguese G3\n",
      "(0.27988259873353316, 'G2')\n",
      "(0.19674616316878907, 'G1')\n",
      "(0.05310582757951958, 'failures')\n",
      "(0.033765992230533455, 'school')\n",
      "(0.02782349017464837, 'Walc')\n",
      "(0.026999852301643697, 'absences')\n",
      "(0.023534387026096903, 'goout')\n",
      "(0.023396782529408102, 'age')\n",
      "(0.022741923874442013, 'famrel')\n",
      "(0.022375539795965172, 'Mjob')\n",
      "(0.022230988799677047, 'Dalc')\n",
      "(0.02139264796640146, 'reason')\n",
      "(0.021072690382148953, 'freetime')\n",
      "(0.019879591423207013, 'Fedu')\n",
      "(0.01983249193726014, 'higher')\n",
      "(0.019640503187246736, 'studytime')\n",
      "(0.019442496530911405, 'Fjob')\n",
      "(0.016919318909505047, 'health')\n",
      "(0.016515597751944486, 'traveltime')\n",
      "(0.014350166163519269, 'address')\n",
      "(0.013701828818365656, 'Medu')\n",
      "(0.011442576381402914, 'internet')\n",
      "(0.01081105390503207, 'nursery')\n",
      "(0.010512362140425306, 'sex')\n",
      "(0.009613225748948342, 'romantic')\n",
      "(0.009233662359755118, 'guardian')\n",
      "(0.008190026202176029, 'activities')\n",
      "(0.006829129089213032, 'famsize')\n",
      "(0.00609897685559307, 'famsup')\n",
      "(0.005000049556189935, 'Pstatus')\n",
      "(0.0036498490337249544, 'schoolsup')\n",
      "(0.003268209442772465, 'paid')\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Over Sampling</th>\n",
       "      <th>Under Sampling</th>\n",
       "      <th>Cluster Centroids</th>\n",
       "      <th>SMOTEENN</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Easy Ensemble Classifier</th>\n",
       "      <th>Deep Neural Network</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Math G1</th>\n",
       "      <td>56.6%</td>\n",
       "      <td>64.0%</td>\n",
       "      <td>55.8%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>71.0%</td>\n",
       "      <td>60.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Math G2</th>\n",
       "      <td>86.4%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>86.4%</td>\n",
       "      <td>88.6%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>87.1%</td>\n",
       "      <td>70.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Math G3</th>\n",
       "      <td>90.7%</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>93.2%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>92.2%</td>\n",
       "      <td>88.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portuguese G1</th>\n",
       "      <td>70.5%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>71.6%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>76.8%</td>\n",
       "      <td>69.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portuguese G2</th>\n",
       "      <td>77.9%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>68.2%</td>\n",
       "      <td>83.2%</td>\n",
       "      <td>81.7%</td>\n",
       "      <td>77.9%</td>\n",
       "      <td>69.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portuguese G3</th>\n",
       "      <td>83.4%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>69.1%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>88.2%</td>\n",
       "      <td>85.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Over Sampling Under Sampling Cluster Centroids SMOTEENN  \\\n",
       "Target                                                                  \n",
       "Math G1               56.6%          64.0%             55.8%    65.4%   \n",
       "Math G2               86.4%          88.7%             86.4%    88.6%   \n",
       "Math G3               90.7%          90.0%             92.4%    93.2%   \n",
       "Portuguese G1         70.5%          72.5%             71.6%    71.5%   \n",
       "Portuguese G2         77.9%          83.6%             68.2%    83.2%   \n",
       "Portuguese G3         83.4%          89.7%             69.1%    89.7%   \n",
       "\n",
       "              Random Forest Easy Ensemble Classifier Deep Neural Network  \n",
       "Target                                                                    \n",
       "Math G1               60.2%                    71.0%               60.6%  \n",
       "Math G2               88.7%                    87.1%               70.7%  \n",
       "Math G3               90.7%                    92.2%               88.9%  \n",
       "Portuguese G1         75.9%                    76.8%               69.3%  \n",
       "Portuguese G2         81.7%                    77.9%               69.9%  \n",
       "Portuguese G3         89.7%                    88.2%               85.3%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_score_table(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "###### So I do not think it is a surprise to see that when we include previous grades that those are the most impactful on the accuracy of the model.\n",
    "###### Likewise their number of absences and other failed classed are a good predictors across all targets.\n",
    "###### Weekend alcohol consumption with going out also have a high correlation. This could be because socializing is cutting too much into study time or maybe there is a correlation between party goers and people that do not take school as serious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
